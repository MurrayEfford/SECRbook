# Multiple sessions

```{r, file = "commoncode.R", echo = FALSE, warning=FALSE, message = FALSE, results="hide"}
# startup code, including library(secr) etc.
```

A 'session' in **secr** is a block of sampling that may be treated as independent from all other sessions. For example, sessions may correspond to trapping grids that are far enough apart that they sample non-overlapping sets of animals. Multi-session data and models combine data from several sessions. Sometimes this is merely a convenience, but it also enables the fitting of models with parameter values that apply across sessions -- data are then effectively pooled with respect to those parameters.

Dealing with multiple sessions adds another layer of complexity, and raises some entirely new issues. This chapter tries for a coherent view of multi-session analyses, covering material that is otherwise scattered.

```{r multisessionsimulation, echo = FALSE, eval = FALSE}
# no need to execute this each time chapter is built
set.seed(123)
grid <- make.grid(nx = 8, ny = 8, detector = 'multi')
msCH <- sim.capthist(grid, popn = list(D = 10, buffer = 100), detectfn = 'HHN',
  detectpar = list(lambda0 = 0.1, sigma = 20), noccasions = 4, nsessions = 3)
for (sess in 1:3) 
    covariates(msCH[[sess]]) <- data.frame(sex = sample(c('f','m'), nrow(msCH[[sess]]),
                                                      replace = TRUE))
write.capthist(msCH, filestem = 'data/msCH', tonumeric = FALSE, covariates = TRUE)
```

## Input

A multi-session capthist object is essentially an R list of single-session capthist objects. We assume the functions `read.capthist` or `make.capthist` will be used for data input (simulated data are considered separately later on).

### Detections

Entering session-specific detections is simple because all detection data are placed in one file or dataframe. Each session uses a character-valued code (the session identifier) in the first column. For demonstration let's assume you have a file 'msCHcapt.txt' with data for 3 sessions, each sampled on 4 occasions.

```{r msCH, echo = FALSE}
con <- file('data/msCHcapt.txt')
ll <- readLines(con)[-(1:2)]
close(con)
ellip <- c('.','.')
st2 <- match('2', substring(ll,1,1))
st3 <- match('3', substring(ll,1,1))
cat (paste0(c(ll[1:5],ellip, ll[st2:(st2+3)],ellip, ll[st3:(st3+3)],ellip), '\n'), sep = '')
```
(clipped lines are indicated by '. .').

Given a trap layout file 'msCHtrap.txt' with the coordinates of the detector sites (A1, A2 etc.), the following call of `read.capthist` will construct a single-session capthist object for each unique code value and combine these in a multi-session capthist: 
```{r readmsCH}
msCH <- read.capthist('data/msCHcapt.txt', 'data/msCHtrap.txt', covnames = 'sex')
```

Use the `summary` method or `str(msCH)` to examine `msCH`. Session-by-session output from `summary` can be excessive; the 'terse' option gives a more compact summary across sessions (columns).
```{r summary}
summary(msCH, terse = TRUE)
```

Sessions are ordered in `msCH` according to their identifiers ('1' before '2', 'Albert' before 'Beatrice' etc.). The order becomes important for matching with session-specific trap layouts and masks, as we see later. The vector of session names (identifiers) may be retrieved with `session(msCH)` or `names(msCH)`.

### Empty sessions

It is possible for there to be no detections in some sessions (but not all!). To create a session with no detections, include a dummy row with the value of the noncapt argument as the animal identifier; the default noncapt value is 'NONE'. The dummy row should have occasion number equal to the number of occasions and some nonsense value (e.g. 0) in each of the other fields (trapID etc.). 

Including individual covariates as additional columns seems to cause trouble in the present version of secr if some sessions are empty, and should be avoided. We drop them from the example file 'msCHcapt2.txt':

```{r msCH2, echo = FALSE}
con <- file('data/msCHcapt2.txt')
ll <- readLines(con)[-(1:2)]
close(con)
ellip <- c('.','.')
st3 <- match('3', substring(ll,1,1))
st4 <- match('4', substring(ll,1,1))
cat (paste0(c(ll[1:4],ellip, ll[st3:(st3+3)],ellip,ll[st4]), '\n'), sep = '')
```
Then,
```{r readmsCH2}
msCH2 <- read.capthist('data/msCHcapt2.txt', 'data/msCHtrap.txt')
summary(msCH2, terse = TRUE)
```

Empty sessions trigger an error in `verify.capthist`; to fit a model suppress verification (e.g., `secr.fit(msCH2, verify = FALSE)`). 

If the first session is empty then either direct the `autoini` option to a later session with e.g., `details = list(autoini = 2)` or provide initial values manually in the `start` argument. 

### Detector layouts

All sessions may share the same detector layout. Then the 'trapfile' argument of `read.capthist` is a single name, as in the example above. The trap layout is repeated as an attribute of each component (single-session) capthist.

Alternatively, each session may have its own detector layout. Unlike the detection data, each session-specific layout is specified in a separate input file or traps object. For `read.capthist` the 'trapfile' argument is then a vector of file names, one for each session. For `make.capthist`, the 'traps' argument may be a list of traps objects, one per session. The first trap layout is used for the first session, the second for the second session, etc.

## Manipulation

The standard extraction and manipulation functions of **secr** (`summary`, `verify`, `covariates`, `subset`, `reduce` etc.) mostly allow for multi-session input, applying the manipulation to each component session in turn. The function `ms` returns TRUE if its argument is a multi-session object and FALSE otherwise.

Plotting a multi-session capthist object (e.g., `plot(msCH)`) will create one new plot for each session unless you specify `add = TRUE`.

Methods that extract attributes from multi-session capthist object will generally return a list in which each component is the result from one session. Thus for the ovenbird mistnetting data `traps(ovenCH)` extracts a list of 5 traps objects, one for each annual session 2005--2009.

The `subset` method for capthist objects has a 'sessions' argument for selecting particular session(s) of a multi-session object.

Table: (\#tab:multisession) Manipulation of multi-session capthist objects. 

| Function | Purpose |  Input  | Output |
|:-----------|:--------------------|:----------------------|:-------------------|
| `join`          | collapse sessions | multi-session capthist | single-session capthist |
| `MS.capthist`   	| build multi-session capthist | several single-session capthist | multi-session capthist |
| `split` | subdivide capthist | single-session capthist | multi-session capthist |

The `split` method for capthist objects (`?split.capthist`) may be used to break a single-session capthist object into a multi-session object, segregating detections by some attribute of the individuals, or by occasion or detector groupings.

## Fitting

Given multi-session capthist input, `secr.fit` automatically fits a multi-session model by maximising the product of session-specific likelihoods [@ebb09]. For fitting a model separately to each session see the later section on [Faster fitting...](#fasterfitting).

### Habitat masks

The default mechanism for constructing a habitat mask in `secr.fit` is to buffer around the trap layout. This extends to multi-session data; buffering is applied to each trap layout in turn.

Override the default buffering mechanism by specifying the 'mask' argument of `secr.fit`. This is necessary if you want to --

1. reduce or increase mask spacing (pixel size; default 1/64 x-range)
2. clip the mask to exclude non-habitat
3. include mask covariates (predictors of local density)
4. define non-Euclidean distances ([secr-noneuclidean.pdf])
5. specify a rectangular mask (type = "traprect" vs type = "trapbuffer")

For any of these you are likely to use the `make.mask` function (the manual alternative is usually too painful to contemplate). If `make.mask` is provided with a list of traps objects as its 'traps' argument then the result is a list of mask objects - effectively, a multi-session mask.

If `addCovariates` receives a list of masks and a single spatial data source then it will add the requested covariate(s) to each mask and return a new list of masks. The single spatial data source is expected to span all the regions; mask points that are not covered receive NA covariate values. As an alternative to a single spatial data source, the `spatialdata` argument may be a list of spatial data sources, one per mask, in the order of the sessions in the corresponding capthist object. 

To eliminate any doubt about the matching of session-specific masks to session-specific detector arrays it is always worth plotting one over the other. We don't have an interesting example, but
```{r plotmasks, fig.width=9, fig.height=3}
masks <- make.mask(traps(msCH), buffer = 80, nx = 32, type = 'trapbuffer')
par (mfrow = c(1,3), mar = c(1,1,3,1))
for (sess in 1:length(msCH)) {
    plot(masks[[sess]])
    plot(traps(msCH)[[sess]], add = TRUE)
    mtext(side=3, paste('session', sess))
}
```

### Session models

The default in `secr.fit` is to treat all parameters as constant across sessions. For detection functions parameterized in terms of cumulative hazard (e.g., 'HHN' or 'HEX') this is equivalent to `model = list(D ~ 1, lambda0 ~ 1, sigma ~ 1)`. Two automatic predictors are provided specifically for multi-session models: 'session' and 'Session'.

#### Session-stratified estimates

A model with lowercase 'session' fits a distinct value of the parameter (D, g0, lambda0, sigma) for each level of `factor(session(msCH))`.

#### Session covariates

Other variation among sessions may be modelled with session-specific covariates. These are provided to `secr.fit` on-the-fly in the argument 'sessioncov' (they cannot be embedded in the capthist object like detector or individual covariates). The value for 'sessioncov' should be a dataframe with one row per session. Each column is a potential predictor in a model formula; other columns are ignored.

Session covariates are extremely flexible. The linear trend of the 'Session' predictor may be emulated by defining a covariate `sessnum = 0:(R-1)` where `R` is the number of sessions. Sessions of different types may be distinguished by a factor-valued covariate. Supposing for the ovenbird dataset we wished to distinguish years 2005 and 2006 from 2007, 2008 and 2009, we could use `earlylate = factor(c('early','early','late','late','late'))`. Quantitative habitat attributes might also be coded as session covariates.

#### Trend across sessions {#simpletrend}
\index{Trend}
\index{Trend | simple}

**secr** is primarily for estimating closed population density (density at one point in time), but multi-session data may also be modelled to describe population trend over time.  A trend model for density may be interesting if the sessions fall in some natural sequence, such as a series of annual samples (as in the ovenbird dataset ovenCH). A model with initial uppercase 'Session' fits a *trend* across sessions using the session number as the predictor. The fitted trend is linear on the link scale; using the default link function for density ('log') this corresponds to exponential growth or decline if samples are equally spaced in time.

The pre-fitted model `ovenbird.model.D` provides an example. The coefficient 'D.Session' is the rate of change in log(D):
```{r trend}
coef(ovenbird.model.D)
```
The overall finite rate of increase (equivalent to Pradel's lambda) is given by 
```{r beta}
beta <- coef(ovenbird.model.D)['D.Session','beta']
sebeta <- coef(ovenbird.model.D)['D.Session','SE.beta']
exp(beta)
```
Confidence intervals may also be back-transformed with `exp`. To back-transform the SE use the delta-method approximation `exp(beta) * sqrt(exp(sebeta^2)-1)` = `r exp(beta) * sqrt(exp(sebeta^2)-1)`.

This is fine for a single overall lambda. However, if you are interested in successive estimates (session 1 to session 2, session 2 to session 3 etc.) the solution is slightly more complicated. A more sophisticated version is provided in the [next section](#trend)

## Trend revisited {#trend}
This section describes methods specifically for population trend, defined as change in density between sessions and measured by the finite rate of increase $\lambda_t = D_{t+1} / D_t$. The flexible methods described here allow the direct estimation of $\lambda_t$, possibly including covariate effects. 

### 'Dlambda' parameterization
\index{Trend !Dlambda parameterization}

We parameterize the density model in terms of the initial density $D_1$ and the finite rates of increase $\lambda_t$ for the remaining sessions ($\lambda_1$ refers to the density increase between Session 1 and Session 2, etc.). Reparameterization of the density model is achieved internally in `secr.fit` by manipulating the density design matrix to provide a new array of mask-cell- and session-specific densities at each evaluation of the full likelihood. This happens when the details argument 'Dlambda' is set to TRUE. The density model (D~) and the fitted coefficients take on a new meaning determined by the internal function `Dfn2`. More explanation is given [later](#Review).

Now, fitting the ovenbird model with D~1 results in two density parameters (density in session 1, constant finite rate of increase across remaining sessions):
```{r direct, cache = TRUE}
msk <- make.mask(traps(ovenCH[[1]]), buffer = 300, nx = 32)
fit1  <- secr.fit(ovenCH, model = D~1, mask = msk, trace = FALSE, 
                 details = list(Dlambda = TRUE))
coef(fit1)
```

Density-relevant beta parameters have names starting with 'D.'[^trend1]. The first is the log initial density; others relate to the $\lambda$ parameters.

[^trend1]: Their indices are listed in component 'D' of the 'parindx' component of the fitted model (e.g. `fit1$parindx$D`), but you are unlikely to need this.

To make the most of the reparameterization we need the special prediction function `predictDlambda` to extract the lambda estimates (the simple `predict` method does not work).

```{r predictDfn2, cache = TRUE}
predictDlambda (fit1)
```

This is an advance on the earlier approach using sdif contrasts, as we have constrained $\lambda$ to a constant. 

### Covariate and other trend models

The method allows many covariate models for $\lambda$. We can fit a time trend in $\lambda$ using:

```{r direct2, cache = TRUE}
fit2  <- secr.fit(ovenCH, model = D~Session, mask = msk, trace = FALSE, 
                 details = list(Dlambda = TRUE))
predictDlambda (fit2)
```

Session-specific $\lambda$ (lower-case 'session') provide a direct comparison with the original analysis:

```{r direct3, cache = TRUE}
fit3  <- secr.fit(ovenCH, model = D~session, mask = msk, trace = FALSE, 
                 details = list(Dlambda = TRUE))
predictDlambda (fit3)
```

The ovenbird population appeared to increase in density for two years and then decline for two years, but the effects are far from significant.

Model selection procedures apply as usual:
```{r msAIC}
AIC(fit1, fit2, fit3, criterion = 'AIC')[,-c(2,5,6)]
```

Session covariates are readily applied. The covariate for the second session predicts $\lambda_1 = D_2/D_1$, for the third session predicts $\lambda_2 = D_3/D_2$, etc. The covariate for the first session is discarded (remember $D_1$ is constant). This all may be confusing, but you can work it out, and it saves extra coding.

```{r direct4, cache = TRUE}
covs <- data.frame(acov = c(0,2,1,1,2))   # a fabricated covariate
fit4  <- secr.fit(ovenCH, model = D~acov, mask = msk, trace = FALSE, 
                 details = list(Dlambda = TRUE), sessioncov = covs)
predictDlambda (fit4)
```

### Fixing coefficients

Another possibility is to fit the model with fixed trend (the second beta 
coefficient corresponds to lambda, before). 

```{r fixedbeta, cache = TRUE}
fit5 <- secr.fit(ovenCH, model = D~1, mask = msk, trace = FALSE,
    details = list(Dlambda = TRUE, fixedbeta = c(NA, log(0.9), NA, NA)))
predictDlambda(fit5)
```

<!-- For comparison, this can be achieved more conventionally by fixing the  -->
<!-- beta coefficient in a model with log-linear trend over sessions (D~Session): -->

<!-- ```{r fixedbeta2, cache = TRUE} -->
<!-- fit6 <- secr.fit(ovenCH, model = D~Session, mask = msk, trace = FALSE, -->
<!--     details = list(Dlambda = FALSE, fixedbeta = c(NA, log(0.9), NA, NA))) -->
<!-- t(sapply(predict(fit6), '[', 'D', )) -->
<!-- ``` -->

### Technical notes and tips {#Review}

`Dfn2` performs some tricky manipulations. You can see the code by typing `secr:::Dfn2`. A column is pre-pended to the density design matrix specifically to model the initial density; this takes the value one in Session 1 and is otherwise zero. Other columns in the design matrix are set to zero for the first session. Session-specific density on the link (log) scale is computed as the cumulative sum across sessions of the initial log density and the modelled log-lambda values.

Note --

* The model allows detector locations and habitat masks to vary between sessions.

* The coding of `Dfn2` relies on a log link function for density.

* Dlambda is ignored for single-session data and conditional-likelihood (CL) models.

* The method is not (yet) suitable for group models.

* The default start values for D in `secr.fit` work well: all lambda are initially 1.0 ($\mbox{log}(\lambda_t) = 0$ for all $t$).

* If session covariates are used in any model, AICcompatible() expects the argument 'sessioncov' to be included in all models.

`r colorize("Tip:","green")` D for session 1 is constant over space. It is not possible in the present version of **secr** to model simultaneous spatial variation in density or $\lambda$, and using Dlambda with a density model that includes spatial covariates will cause an error.

<!-- `r colorize("Tip:","green")` Underestimation of sampling variance is expected when a trend model is fitted to temporal samples with incomplete population turnover between sessions. The product likelihood assumes a new realisation of the underlying population process for each session. If in actuality much of the sampled population remains the same (the same individuals in the same home ranges) then the precision of the trend coefficient will be overstated.  -->

<!-- The effect is often small. Possible solutions are to fit an open population model (e.g., in **openCR** [@es20]) or to apply some form of bootstrapping. -->

## Simulation

Back at the start of this document we used `sim.capthist` to generate `msCH`, a simple multi-session capthist. Here we look at various extensions. Generating SECR data is a 2-stage process. The first stage simulates the locations of animals to create an object of class 'popn'; the second stage generates samples from that population according to a particular sampling regime (detector array, number of occasions etc.). 

### Simulating multi-session populations

By default `sim.capthist` uses `sim.popn` to generate a new population independently for each session. Centres are placed within a rectangular region obtained by buffering around a 'core' (the traps object passed to `sim.capthist`). 

The session-specific populations may also be prepared in advance as a list of 'popn' objects (use nsessions > 1 in `sim.popn`). This allows greater control. In particular, the population density may be varied among sessions by making argument D a vector of session-specific densities. Other arguments of `sim.popn` do not yet accept multi-session input -- it might be useful for 'core' to accept a list of traps objects (or a list of mask objects if model2D = "IHP").

We can also put aside the basic assumption of independence among sessions and simulate a single population open to births, deaths and movement between sessions. This does not correspond to any model that can be fitted in `secr`, but it allows the effects of non-independence to be examined. See `?turnover` for further explanation.

### Multi-session sampling

A multi-session population prepared in advance is passed as the popn argument of `sim.capthist`, replacing the usual list (D, buffer etc.).

The argument 'traps' may be a list of length equal to nsessions. Each component potentially differs not just in detector locations, but also with respect to detector type ('detector') and resighting regime ('markocc'). The argument 'noccasions' may also be a vector with a different number of occasions in each session. 

## Problems

There are problems specific to multi-session data.

### Failure of autoini

Numerical maximisation of the likelihood requires a starting set of parameter values. This is either computed internally with the function `autoini` or provided by the user. Given multi-session data, the default procedure is for `secr.fit` to apply `autoini` to the first session only. If the data for that session are inadequate or result in parameter estimates that are extreme with respect to the remaining sessions then model fitting may abort. One solution is to provide start values manually, but that can be laborious. A quick fix is often to switch the session used to compute starting values by changing the details option 'autoini'. For example
```{r autoini, cache = TRUE, eval = FALSE}
fit0 <- secr.fit(ovenCH, mask = msk, details = list(autoini = 2), trace = FALSE)
```
A further option is to combine the session data into a single-session capthist object with `details = list(autoini = "all")`; the combined capthist is used only by `autoini`. This is experimental in **secr** 4.6.


### Covariates with incompatible factor levels

Individual or detector covariates used in a multi-session model obviously must appear in each of the component sessions. It is less obvious, and sometimes annoying, that a factor (categorical) covariate should have exactly the same levels in the same order in each component session. The `verify` methods for capthist objects checks that this is in fact the case (remember that `verify` is called by `secr.fit` unless you suppress it).

A common example might be an individual covariate 'sex' with the levels "f" and "m". If by chance only males are detected in one of the sessions, and as a result the factor has a single level "m" in that session, then `verify` will give a warning. 

The solution is to force all sessions to use the same factor levels. The function `shareFactorLevels` is provided for this purpose.

## Speed  {#fasterfitting}

Fitting a multi-session model with each parameter stratified by session is unnecessarily slow. In this case no data are pooled across sessions and it is better to fit each session separately. If your data are already in a multi-session capthist object then the speedy solution is

```{r lapply, cache = TRUE}
fits <- lapply(ovenCH, secr.fit, mask = msk, trace = FALSE)
class(fits) <- 'secrlist'
predict(fits)
```

The first line (`lapply`) creates a list of 'secr' objects. The `predict` method works once we set the class attribute to 'secrlist' (or you could `lapply(fits, predict)`).

```{r fullfit, cache = TRUE}
fits2 <- secr.fit(ovenCH, model=list(D~session, g0~session, sigma~session), 
                  mask = msk, trace = FALSE)
```

What if we wish to compare ths model with a less general one (i.e. with some parameter values shared across sessions)? For that we need the number of parameters, log likelihood and AIC summed across sessions:
```{r sumAIC}
apply(AIC(fits)[,3:5],2,sum)
AIC(fits2)[,3:5]
```

AICc is not a simple sum of session-specific AICc and should be calculated manually (hint: use `sapply(ovenCH, nrow)` for session-specific sample sizes).

The unified model fit and separate model fits with `lapply` give essentially the same answers, and the latter approach is faster by a factor of `r  round(fits2$proctime / sum(unlist(sapply(fits, '[', 'proctime'))))`.

Using `lapply` does not work if some arguments of `secr.fit` other than 'capthist' themselves differ among sessions (as when 'mask' is a list of session-specific masks). Then we can use either a 'for' loop or the slightly more demanding function `mapply`, with the same gain in speed.
```{r mapply, cache = TRUE}
# one mask per session
masks <- make.mask(traps(ovenCH), buffer = 300, type = 'trapbuffer', nx = 32)  
fits3 <- mapply(secr.fit, ovenCH, mask = masks, MoreArgs = list(trace = FALSE), 
                SIMPLIFY = FALSE)
class(fits3) <- 'secrlist'
```

## Caveats

### Independence is a strong assumption

If sessions are not truly independent then expect confidence intervals to be too short. This is especially likely when a trend model is fitted to temporal samples with incomplete population turnover between sessions. The product likelihood assumes a new realisation of the underlying population process for each session. If in actuality much of the sampled population remains the same (the same individuals in the same home ranges) then the precision of the trend coefficient will be overstated. Either an open population model is needed (e.g., **openCR** [@es20]) or extra work will be needed to obtain credible confidence limits for the trend (probably some form of bootstrapping).

### Parameters are assumed constant by default

Output from `predict.secr` for a multi-session model is automatically stratified by session even when the model does not include 'session', 'Session' or any session covariate as a predictor (the output simply repeats the constant estimates for each session).

[secr-trend.pdf]: https://www.otago.ac.nz/density/pdfs/secr-trend.pdf
[secr-noneuclidean.pdf]: https://www.otago.ac.nz/density/pdfs/secr-noneuclidean.pdf
[secr-multisession.pdf]: https://www.otago.ac.nz/density/pdfs/secr-multisession.pdf
